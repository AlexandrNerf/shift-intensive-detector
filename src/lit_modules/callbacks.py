import os
import csv
import torch
import logging
from lightning.pytorch import LightningModule, Trainer
from lightning.pytorch.callbacks import Callback, ModelCheckpoint
from hydra.utils import get_original_cwd

log = logging.getLogger(__name__)

class JITModelCheckpoint(ModelCheckpoint):
    def __init__(self, *args, **kwargs):
        """
        –ö–æ–ª–ª–±–µ–∫ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –∫–∞–∫ –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, —Ç–∞–∫ –∏ –≤ JIT —Ñ–æ—Ä–º–∞—Ç–µ.
        """
        super().__init__(*args, **kwargs)  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ ModelCheckpoint

    def on_save_checkpoint(self, trainer, pl_module, checkpoint):
        """
        –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ checkpoint —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è.
        """
        # –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ ModelCheckpoint
        result = super().on_save_checkpoint(trainer, pl_module, checkpoint)

        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ LightningModule
        model = pl_module.model

        if not os.path.exists(self.dirpath):
            os.makedirs(self.dirpath)

        # –°–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å —Å –ø–æ–º–æ—â—å—é torch.jit.script
        try:
            jit_model = torch.jit.script(model)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º `script` –¥–ª—è –º–æ–¥–µ–ª–∏
        except Exception as e:
            log.info(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ –º–æ–¥–µ–ª–∏ –≤ JIT: {e}")
            return result

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º JIT –º–æ–¥–µ–ª—å
        model_path = os.path.join(self.dirpath, f"{self.filename.format(epoch=trainer.current_epoch)}_jit.pt")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º JIT –º–æ–¥–µ–ª—å
        torch.jit.save(jit_model, model_path)
        
        return result


class HardNegativeLogger(Callback):
    def __init__(self, output_dir, csv_name="hnm.csv"):
        super().__init__()
        self.train_loader = None
        self.eval_loader = None
        self.csv_path_val = os.path.join(output_dir, 'val_' + csv_name)
        self.csv_path_train = os.path.join(output_dir, 'train_' + csv_name)
        self.results = []

    @torch.no_grad()
    def on_fit_end(self, trainer: Trainer, pl_module: LightningModule):
        if trainer.val_dataloaders is not None and len(trainer.val_dataloaders) > 0:
            self.eval_loader = trainer.val_dataloaders
        if trainer.train_dataloader is not None and len(trainer.train_dataloader) > 0:
            self.train_loader = trainer.train_dataloader
        if self.eval_loader is None and self.train_loader is None:
            log.info("‚ö†Ô∏è HardNegativeLogger: no train_loader and no eval_loader provided. Please check you enabled")
            return

        pl_module.eval()
        device = pl_module.device
        log.info("üîç Collecting hard negatives...")

        for batch_idx, batch in enumerate(self.eval_loader):
            images, labels, paths = batch

            for sample_idx, (img, gt, path) in enumerate(zip(images, labels, paths)):
                img = img.unsqueeze(0).to(device)  # –¥–æ–±–∞–≤–ª—è–µ–º batch dim

                output = pl_module((img, [gt], path))
                
                preds = output.get("preds", [()])  # –±–µ—Ä–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è 1-–≥–æ –ø—Ä–∏–º–µ—Ä–∞]
                loss_val = output.get("loss", None)

                for pred_text, conf in preds:
                    entry = {
                        "batch_idx": batch_idx,
                        "sample_idx": sample_idx,
                        "path": path,
                        "pred_text": pred_text,
                        "confidence": float(conf),
                        "loss": loss_val,
                        "gt": gt
                    }
                    self.results.append(entry)
    
        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º csv
        with open(self.csv_path_val, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=self.results[0].keys())
            writer.writeheader()
            writer.writerows(self.results)

        self.results = []
        # —Ä–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ–º preds: list[list[tuple[text, conf]]]
        for batch_idx, batch in enumerate(self.train_loader):
            images, labels, paths = batch

            for sample_idx, (img, gt, path) in enumerate(zip(images, labels, paths)):
                img = img.unsqueeze(0).to(device)  # –¥–æ–±–∞–≤–ª—è–µ–º batch dim

                output = pl_module((img, [gt], path))
                
                preds = output.get("preds", [()])  # –±–µ—Ä–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è 1-–≥–æ –ø—Ä–∏–º–µ—Ä–∞]
                loss_val = output.get("loss", None)

                for pred_text, conf in preds:
                    entry = {
                        "batch_idx": batch_idx,
                        "sample_idx": sample_idx,
                        "path": path,
                        "pred_text": pred_text,
                        "confidence": float(conf),
                        "loss": loss_val,
                        "gt": gt
                    }
                    self.results.append(entry)
        with open(self.csv_path_train, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=self.results[0].keys())
            writer.writeheader()
            writer.writerows(self.results)

        log.info(f"‚úÖ Hard negatives saved to: {self.csv_path_val}, {self.csv_path_train}")
